{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "FEEDBACK_PROJECT_ID = os.getenv(\"FEEDBACK_PROJECT_ID\")\n",
    "PUBLISHING_PROJECT_ID = os.getenv(\"PUBLISHING_PROJECT_ID\")\n",
    "FEEDBACK_TABLE = os.getenv(\"FEEDBACK_TABLE\")\n",
    "PUBLISHING_TABLE = os.getenv(\"PUBLISHING_TABLE\")\n",
    "LABELLED_FEEDBACK_TABLE = os.getenv(\"LABELLED_FEEDBACK_TABLE\")\n",
    "OPENAI_LABEL_FEEDBACK_TABLE = os.getenv(\"OPENAI_LABELLED_FEEDBACK_TABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback_by_record_id(N: int) -> list:\n",
    "    \"\"\"\n",
    "    Extracts feedback records from BigQuery, grouped by\n",
    "    feedback_record_id and concatenating response_value\n",
    "    :return: Dictionary containing feedback records\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=PUBLISHING_PROJECT_ID, location=\"europe-west2\")\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "          feedback_record_id,\n",
    "          STRING_AGG(response_value, ' '\n",
    "          ORDER BY\n",
    "            created) AS concatenated_response_value,\n",
    "            rand() as r\n",
    "        FROM\n",
    "          @publishing_table\n",
    "          WHERE DATE(created) >= \"2024-01-01\"\n",
    "        GROUP BY\n",
    "          feedback_record_id\n",
    "        ORDER BY\n",
    "          r\n",
    "      LIMIT (@N)\n",
    "    \"\"\"\n",
    "    query = query.replace(\"@publishing_table\", str(PUBLISHING_TABLE))\n",
    "    query = query.replace(\"@N\", str(N))\n",
    "    query_job = client.query(query=query)\n",
    "    result = query_job.result()\n",
    "\n",
    "    records = []\n",
    "    for row in result:\n",
    "        record = dict(row)\n",
    "        records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unlabelled feedback records for labelling with OpenAI\n",
    "records = get_feedback_by_record_id(5)\n",
    "type(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK FOR PII IN feedback - regenerate sample if so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelled_feedback_sample(N: int) -> list:\n",
    "    \"\"\"\n",
    "    Extracts labelled feedback records from a BigQuery table\n",
    "    :return: Dictionary containing feedback records\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=FEEDBACK_PROJECT_ID, location=\"europe-west2\")\n",
    "    query = \"\"\"\n",
    "      SELECT \n",
    "        *, \n",
    "        rand() AS r \n",
    "      FROM \n",
    "        @labelled_feedback_table \n",
    "      ORDER BY \n",
    "        r \n",
    "      LIMIT (@N)\n",
    "    \"\"\"\n",
    "    query = query.replace(\"@labelled_feedback_table\", str(LABELLED_FEEDBACK_TABLE))\n",
    "    query = query.replace(\"@N\", str(N))\n",
    "    query_job = client.query(query=query)\n",
    "    result = query_job.result()\n",
    "\n",
    "    records = []\n",
    "    for row in result:\n",
    "        record = dict(row)\n",
    "        records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labelled feedback records for few-shot prompting\n",
    "labelled_records = get_labelled_feedback_sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: labelled feedback has already been reviewed for PII and any offending records excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonify labelled feedback records for injection into the prompt\n",
    "def jsonify_feedback(records: list, labelled=False):\n",
    "    \"\"\"\n",
    "    Create json string from feedback\n",
    "    :return: json string of feedback records\n",
    "    \"\"\"\n",
    "    subs = []\n",
    "    for i, item in enumerate(records):\n",
    "        response_value = item[\"concatenated_response_value\"]\n",
    "        subs.append(\n",
    "            {\n",
    "                \"id\": item[\"feedback_record_id\"],\n",
    "                \"feedback\": response_value,\n",
    "                \"label\": [item[\"labels\"] if labelled else \"\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return json.dumps(subs, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_subs_json = jsonify_feedback(labelled_records, labelled=True)\n",
    "new_subs_json = jsonify_feedback(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"context length: {len(labelled_subs_json)}\")\n",
    "# print(f\"context length: {len(new_subs_json)}\")\n",
    "print(new_subs_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prompt = f\"\"\"\n",
    "    You are an expert at providing consistent categorisation of user feedback for the UK government left via the website www.gov.uk. \n",
    "    You are given user feedback, with an aribirtrary id number, and you must provide a label or set of labels for the feedback to categorise it.\n",
    "    In the rare event there is no coherent theme within a feedback record, label it as \"Unknown\".\n",
    "    If the feedback is clearly spam, label it as \"Spam\".\n",
    "    Always return valid JSON.\n",
    "\n",
    "    Short examples:\n",
    "    {labelled_subs_json}\n",
    "\n",
    "    Label the following data. Only return the id and the labels, do not return the feedback.\n",
    "    \n",
    "    {new_subs_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call OpenAI to generate labels for feedback records\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": label_prompt,\n",
    "            }  # type: ignore\n",
    "        ],\n",
    "        max_tokens=250,\n",
    "        temperature=0.75,\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    # synth_records = json.loads(completion.choices[0].message.content)\n",
    "    open_labelled_records = completion.choices[0].message.content\n",
    "except Exception as e:\n",
    "    print(f\"OpenAI request failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open_labelled_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write labels to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_labelled___df = pd.DataFrame(json.loads(open_labelled_records)[\"results\"]).rename(columns={\"id\":\"feedback_record_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_bigquery(table_id: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Writes data to BigQuery\n",
    "    \"\"\"\n",
    "    # Initialize a BigQuery client\n",
    "    client = bigquery.Client(project=FEEDBACK_PROJECT_ID)\n",
    "\n",
    "    # Define schema for the table\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"feedback_record_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"label\", \"STRING\", mode=\"REPEATED\"),\n",
    "    ]\n",
    "\n",
    "    # Define job configuration\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=schema, write_disposition=\"WRITE_TRUNCATE\"\n",
    "    )\n",
    "\n",
    "    # Write DataFrame to BigQuery\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "\n",
    "    # Wait for the job to complete\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Table {table_id} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write feedback to BQ table\n",
    "write_to_bigquery(table_id=OPENAI_LABEL_FEEDBACK_TABLE, df=openai_labelled___df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Generate synthetic data based on labelled feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_prompt = f\"\"\"\n",
    "    You are an expert at generating synthetic records based on a few short examples.\n",
    "    The following examples are feedback records from the UK government website www.gov.uk.\n",
    "    You are given a few examples of feedback records and asked to generate a synthetic dataset of 10 feedback records that are similar in theme and tone to the examples.\n",
    "\n",
    "    Short examples:\n",
    "    {labelled_subs_json}\n",
    "\n",
    "    Synthetic records:\n",
    "    \"\"\"\n",
    "\n",
    "print(synth_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": synth_prompt,\n",
    "            }  # type: ignore\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.75,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    # synth_records = json.loads(completion.choices[0].message.content)\n",
    "    open_labelled_records = completion.choices[0].message.content\n",
    "except Exception as e:\n",
    "    print(f\"OpenAI request failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
