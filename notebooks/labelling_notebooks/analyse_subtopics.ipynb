{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from google.cloud import bigquery\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEEDBACK_PROJECT = os.environ[\"FEEDBACK_PROJECT\"]\n",
    "GSDMM_TOPICS_TABLE = os.environ[\"GSDMM_TOPICS_TABLE\"]\n",
    "PROCESS_TABLE = os.environ[\"PROCESS_TABLE\"]\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID = \"dd526f3c-efbc-11ee-a5ac-4200a9fe0102\"  # This UUID is the output of the FaaS subtopic pipeline on our 6mth FaaS topic pipeline outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_text(text: str) -> str:\n",
    "    \"\"\"Remove newlines, multiple whitespace, and leading/trailing whitespace.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_sql_file(file_path: str) -> str:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        query = file.read()\n",
    "    return query\n",
    "\n",
    "\n",
    "def replace_kwargs(query, **kwargs) -> str:\n",
    "    for key, value in kwargs.items():\n",
    "        placeholder = \"@\" + key\n",
    "        query = query.replace(placeholder, value)\n",
    "    return query\n",
    "\n",
    "\n",
    "def load_data(query: str, project: str) -> list[dict] | None:\n",
    "    try:\n",
    "        client = bigquery.Client(project=project)\n",
    "        query_job = client.query(query)\n",
    "        result = [dict(row) for row in query_job.result()]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_bq_client() -> bigquery.Client:\n",
    "    \"\"\"\n",
    "    Create and return a BigQuery client.\n",
    "    \"\"\"\n",
    "    return bigquery.Client()\n",
    "\n",
    "\n",
    "def run_query(query: str, project: str):\n",
    "    \"\"\"\n",
    "    Run the query and return the results.\n",
    "    \"\"\"\n",
    "    client = create_bq_client()\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.use_legacy_sql = False\n",
    "    query_job = client.query(query, job_config=job_config, project=project)\n",
    "    return query_job.result()\n",
    "\n",
    "\n",
    "# Analyse GSDMM subtopics if they exist\n",
    "def check_uuid_exists(uuid):\n",
    "    query = read_sql_file(\"check_uuid.sql\")\n",
    "    query = replace_kwargs(\n",
    "        query=query,\n",
    "        project=FEEDBACK_PROJECT,\n",
    "        topics_table=GSDMM_TOPICS_TABLE,\n",
    "    )\n",
    "    results = load_data(query, FEEDBACK_PROJECT)\n",
    "    uuid_list = [result[\"uuid\"] for result in results]\n",
    "    if not uuid in uuid_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_subtopics(uuid: str):\n",
    "    if check_uuid_exists(uuid):\n",
    "        query = read_sql_file(\"get_subtopics.sql\")\n",
    "        query = replace_kwargs(\n",
    "            query=query,\n",
    "            project=FEEDBACK_PROJECT,\n",
    "            topics_table=GSDMM_TOPICS_TABLE,\n",
    "            UUID=uuid,\n",
    "        )\n",
    "        results = load_data(query, FEEDBACK_PROJECT)\n",
    "        return results\n",
    "\n",
    "\n",
    "def extract_bigrams(uuid):\n",
    "    # For each topic, save one instance of the terms_list array output in the results dict\n",
    "    query = read_sql_file(\"extract_bigrams.sql\")\n",
    "    query = replace_kwargs(\n",
    "        query=query,\n",
    "        project=FEEDBACK_PROJECT,\n",
    "        topics_table=GSDMM_TOPICS_TABLE,\n",
    "        UUID=uuid,\n",
    "    )\n",
    "    results = load_data(query, FEEDBACK_PROJECT)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Format results to return a dictionary of the form {topic: {subtopic: [bigram1, bigram2, ...]}}\n",
    "def format_bigrams(results):\n",
    "    bigrams = {}\n",
    "\n",
    "    # Loop over the results and create a dictionary of bigrams\n",
    "    for result in results:\n",
    "        bert_topic = result[\"BERT_topic\"]\n",
    "        gsdmm_topic = result[\"GSDMM_topic\"]\n",
    "        terms = result[\"unique_terms\"]\n",
    "        if bert_topic not in bigrams:\n",
    "            bigrams[bert_topic] = {}\n",
    "        bigrams[bert_topic][gsdmm_topic] = terms\n",
    "\n",
    "    # Replace Other bigrams with Other because they are not useful\n",
    "    for _, subtopics in bigrams.items():\n",
    "        if \"Other\" in subtopics:\n",
    "            subtopics[\"Other\"] = [\"Other\"]\n",
    "\n",
    "    return bigrams\n",
    "\n",
    "\n",
    "# Extract results and visualise\n",
    "def extract_top_docs(uuid):\n",
    "    query = read_sql_file(\"extract_top_docs.sql\")\n",
    "\n",
    "    query = replace_kwargs(\n",
    "        query=query,\n",
    "        project=FEEDBACK_PROJECT,\n",
    "        topics_table=GSDMM_TOPICS_TABLE,\n",
    "        UUID=uuid,\n",
    "    )\n",
    "    results = load_data(query, FEEDBACK_PROJECT)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Format results to return a dictionary of the form {BERT_topic: {GSDMM_topic: [sentence1, sentence2, ...]}}\n",
    "def format_top_docs(results):\n",
    "    top_docs = {}\n",
    "\n",
    "    # Loop over the results and create a dictionary of top docs\n",
    "    for result in results:\n",
    "        bert_topic = result[\"BERT_topic\"]\n",
    "        gsdmm_topic = result[\"GSDMM_topic\"]\n",
    "        sentence = result[\"sentence\"]\n",
    "        if bert_topic not in top_docs:\n",
    "            top_docs[bert_topic] = {}\n",
    "        if gsdmm_topic not in top_docs[bert_topic]:\n",
    "            top_docs[bert_topic][gsdmm_topic] = []\n",
    "        top_docs[bert_topic][gsdmm_topic].append(sentence)\n",
    "\n",
    "    return top_docs\n",
    "\n",
    "\n",
    "def format_docs_and_grams(formatted_bigrams, formatted_docs):\n",
    "    topics_dict = {}\n",
    "    if formatted_bigrams.keys() == formatted_docs.keys():\n",
    "        for bert_topic in formatted_bigrams.keys():\n",
    "            topics_dict[bert_topic] = {}\n",
    "\n",
    "            for topic in formatted_bigrams[bert_topic].keys():\n",
    "                topics_dict[bert_topic][topic] = {}\n",
    "                topics_dict[bert_topic][topic][\"bigrams\"] = formatted_bigrams[\n",
    "                    bert_topic\n",
    "                ][topic]\n",
    "                topics_dict[bert_topic][topic][\"docs\"] = formatted_docs[bert_topic][\n",
    "                    topic\n",
    "                ]\n",
    "    else:\n",
    "        print(\"Topics are not equivalent in docs and bigrams\")\n",
    "    return topics_dict\n",
    "    # This creates {bert_topic: {gibss_topic: {bigrams: [bigram_1, bigram_2, ...]}, docs: {gibbs_topic: [doc1, doc2, ...]}}}\n",
    "\n",
    "\n",
    "def generate_completion(prompt: str):\n",
    "    \"\"\"\n",
    "    Generate completion using OpenAI API.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=API_KEY)\n",
    "    return client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.5,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "\n",
    "\n",
    "def create_subtopic_labels(topics_dict: dict, bert_topic: int):\n",
    "    if bert_topic in topic_cache.keys():\n",
    "        return\n",
    "\n",
    "    labels = {}\n",
    "    for key, value in topics_dict[bert_topic].items():\n",
    "        topic_names = key\n",
    "\n",
    "        topic_values = value\n",
    "        for topic_name in [topic_names]:\n",
    "            bigrams = topic_values[\"bigrams\"]\n",
    "            docs = topic_values[\"docs\"]\n",
    "            prompt_bigrams = \", \".join(x for x in bigrams)\n",
    "            prompt_docs = \"\\n\".join([f\"- {_format_text(text)}\" for text in docs])\n",
    "\n",
    "            # # Create a prompt\n",
    "            prompt = f\"\"\"\n",
    "            This is a list of texts where each collection of texts describe a topic. After each collection of texts, the name of the topic they represent is mentioned as a short-highly-descriptive title less than ten words long.\n",
    "            Instances of PII in the texts have been replaced with the type of PII surrounded by square brackets e.g. [PERSON_NAME]; these do not have any influence on the topic description.\n",
    "            ---\n",
    "            - I tried to renew the vehicle tax online several times today around 3.30pm, but on each occasion, after entering the 16 digit reference number, the system goes back to \"START\" again and again\n",
    "            - not accepting the reference number\n",
    "            - taxing my motor bike\n",
    "            - Would not accept 16 digit reference no either by phone or website\n",
    "\n",
    "            Keywords: tax car, try tax, tax vehicle, car tax, vehicle tax, try pay, road tax, not accept, debit card, tax try\n",
    "            Topic Name: Online vechile tax\n",
    "            ---\n",
    "            - My phone number no longer works and I can't go to my Universal Credit account\n",
    "            - No text messages received, all other details are correct but I cannot update my journal and I won't get paid this month if it isn't done soon.\n",
    "            - I am unable to sign in to my universal credit. The page is telling me that it is unavailable.\n",
    "            - My name is [PERSON_NAME], I am trying to sign into my account.\n",
    "\n",
    "            Keywords: universal credit, try sign, try log, account try, student finance, credit account, can not, sign universal, sign account, sign try\n",
    "            Topic Name: Universal credit / student finance sign in\n",
    "            ---\n",
    "            Topic:\n",
    "            Sample texts from this topic:\n",
    "            {prompt_docs}\n",
    "            Keywords: {prompt_bigrams}\n",
    "            Topic name:\n",
    "            \"\"\"\n",
    "\n",
    "            # Check if the topic is in the cache\n",
    "            if topic_name not in topic_cache.keys():\n",
    "                try:\n",
    "                    completion = generate_completion(prompt)\n",
    "                    topic_cache[topic_name] = completion.choices[0].message.content\n",
    "                except Exception as e:\n",
    "                    print(f\"OpenAI request failed: {e}\")\n",
    "\n",
    "            # Add the topic and label to the dictionary\n",
    "            labels[topic_name] = topic_cache[topic_name]\n",
    "            # Add topic_name: labels to the topic_cache\n",
    "            topic_cache[bert_topic] = labels\n",
    "\n",
    "\n",
    "def count_subtopics(gibbs_results: list[dict], bert_topic: int, topic_cache: dict):\n",
    "    filter_relevant_data = [x for x in gibbs_results if x[\"BERT_topic\"] == bert_topic]\n",
    "    gibbs_topics = set(x[\"GSDMM_topic\"] for x in filter_relevant_data)\n",
    "    gibbs_topic_counts = {topic: 0 for topic in gibbs_topics}\n",
    "    for record in filter_relevant_data:\n",
    "        gibbs_topic_counts[record[\"GSDMM_topic\"]] += 1\n",
    "    return gibbs_topic_counts\n",
    "\n",
    "\n",
    "def create_gibbs_barchart(\n",
    "    gibbs_results: list[dict], bert_topic: int, topic_cache: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    For a given bert topic, create a bar chart of subtopic counts and subtopic labels so you can see what's going on.\n",
    "\n",
    "    Args:\n",
    "        gibbs_results: list[dict] = list of dictionaries containing the gibbs results queried from BQ\n",
    "        bert_topic: int = bert topic of interest that we want to visualise\n",
    "    \"\"\"\n",
    "\n",
    "    gibbs_topic_counts = count_subtopics(\n",
    "        gibbs_results=gibbs_results, bert_topic=bert_topic, topic_cache=topic_cache\n",
    "    )\n",
    "\n",
    "    # Define ordered list: Will always be 10 unless we change the subtopic pipeline\n",
    "    desired_order = [\n",
    "        \"Other\",\n",
    "        \"Topic 0\",\n",
    "        \"Topic 1\",\n",
    "        \"Topic 2\",\n",
    "        \"Topic 3\",\n",
    "        \"Topic 4\",\n",
    "        \"Topic 5\",\n",
    "        \"Topic 6\",\n",
    "        \"Topic 7\",\n",
    "        \"Topic 8\",\n",
    "        \"Topic 9\",\n",
    "    ]\n",
    "\n",
    "    topics = [x for x in desired_order if x in gibbs_topic_counts]\n",
    "    counts = [gibbs_topic_counts[x] for x in topics]\n",
    "    try:\n",
    "        topics = [topic_cache[key] for key in desired_order if key in topic_cache]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}, most likely topic_cache doesn't exist\")\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig = go.Figure(data=go.Bar(x=topics, y=counts))\n",
    "\n",
    "    # Set the chart title and axis labels\n",
    "    fig.update_layout(\n",
    "        title=f\"Subtopics for BERT topic: {bert_topic}\",\n",
    "        xaxis_title=\"Subtopic\",\n",
    "        yaxis_title=\"Count\",\n",
    "        legend=dict(orientation=\"h\", x=0.0, y=-0.15),\n",
    "        font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "        plot_bgcolor=\"white\",\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            showgrid=True,\n",
    "            linecolor=\"black\",\n",
    "            tickmode=\"auto\",\n",
    "            nticks=15,\n",
    "            tickformat=\"%b %d\",\n",
    "        ),\n",
    "        yaxis=dict(showline=True, showgrid=True, linecolor=\"black\"),\n",
    "        margin=dict(l=20, r=20, t=40, b=80),\n",
    "    )\n",
    "\n",
    "    # Show the chart\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbs_results = get_subtopics(UUID)\n",
    "raw_bigrams = extract_bigrams(UUID)\n",
    "formatted_bigrams = format_bigrams(raw_bigrams)\n",
    "raw_top_docs = extract_top_docs(UUID)\n",
    "formatted_docs = format_top_docs(raw_top_docs)\n",
    "topics_dict = format_docs_and_grams(formatted_bigrams, formatted_docs)\n",
    "topic_cache = {\"Other\": \"Other\"}\n",
    "create_subtopic_labels(\n",
    "    topics_dict, 0\n",
    ")  # Change number here to label a different BERT topic <- if already labelled it won't call OpenAI again though!\n",
    "print(topic_cache)  # To see our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gibbs_barchart(\n",
    "    gibbs_results, 0, topic_cache\n",
    ")  # Visualise a subtopic, if it exists in topic cache it will use the labels instead of generic topic names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
