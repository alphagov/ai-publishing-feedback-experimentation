{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from google.cloud import bigquery\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEEDBACK_PROJECT = os.environ[\"FEEDBACK_PROJECT\"]\n",
    "BERT_TOPICS_TABLE = os.environ[\"BERT_TOPICS_TABLE\"]\n",
    "BERT_TERMS_TABLE = os.environ[\"BERT_TERMS_TABLE\"]\n",
    "BERT_TOT_TABLE = os.environ[\"BERT_TOT_TABLE\"]  # Where TOT = topics over time\n",
    "PROCESS_TABLE = os.environ[\"PROCESS_TABLE\"]\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID = \"0db212fe-06fb-11ef-b6d9-acde48001122\"  # Output of the FaaS bert pipeline for our 6 mth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_text(text: str) -> str:\n",
    "    \"\"\"Remove newlines, multiple whitespace, and leading/trailing whitespace.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_sql_file(file_path: str) -> str:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        query = file.read()\n",
    "    return query\n",
    "\n",
    "\n",
    "def replace_kwargs(query, **kwargs) -> str:\n",
    "    for key, value in kwargs.items():\n",
    "        placeholder = \"@\" + key\n",
    "        query = query.replace(placeholder, value)\n",
    "    return query\n",
    "\n",
    "\n",
    "def load_data(query: str, project: str) -> list[dict] | None:\n",
    "    try:\n",
    "        client = bigquery.Client(project=project)\n",
    "        query_job = client.query(query)\n",
    "        result = [dict(row) for row in query_job.result()]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_bq_client() -> bigquery.Client:\n",
    "    \"\"\"\n",
    "    Create and return a BigQuery client.\n",
    "    \"\"\"\n",
    "    return bigquery.Client()\n",
    "\n",
    "\n",
    "def run_query(query: str, project: str):\n",
    "    \"\"\"\n",
    "    Run the query and return the results.\n",
    "    \"\"\"\n",
    "    client = create_bq_client()\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.use_legacy_sql = False\n",
    "    query_job = client.query(query, job_config=job_config, project=project)\n",
    "    return query_job.result()\n",
    "\n",
    "\n",
    "def update_topic_dict(topic_dict: dict[str, dict[str, list]], row) -> None:\n",
    "    \"\"\"\n",
    "    Update the topic dictionary with the row data.\n",
    "    \"\"\"\n",
    "    if row.topics not in topic_dict:\n",
    "        topic_dict[row.topics] = {\"text_value\": [], \"keywords\": []}\n",
    "\n",
    "    topic_dict[row.topics][\"text_value\"].append(row.text_value)\n",
    "    topic_dict[row.topics][\"keywords\"].append(row.term)\n",
    "\n",
    "\n",
    "def format_text_values(text_values: list) -> str:\n",
    "    \"\"\"\n",
    "    Format the text values for a topic.\n",
    "    \"\"\"\n",
    "    return \"\\n\".join([f\"- {_format_text(text)}\" for text in text_values])\n",
    "\n",
    "\n",
    "def format_keywords(keywords: list) -> str:\n",
    "    \"\"\"\n",
    "    Format the keywords for a topic.\n",
    "    \"\"\"\n",
    "    return \", \".join(keywords)\n",
    "\n",
    "\n",
    "def generate_completion(prompt: str):\n",
    "    \"\"\"\n",
    "    Generate completion using OpenAI API.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=API_KEY)\n",
    "    return client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.5,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "\n",
    "\n",
    "def create_topic_labels(\n",
    "    query: str,\n",
    "    UUID: str,\n",
    "    FEEDBACK_PROJECT: str,\n",
    "    TOPICS_TABLE: str,\n",
    "    N_GRAM_TABLE: str,\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Function which takes a BQ table as input containing a \"topic\", \"probability\" and \"text column,\n",
    "    effectively the output of a BERTopic topic model. For each topic, it orders the text column by\n",
    "    probability and returns the top 10 rows for each topic. These ten text records are then passed\n",
    "    to a gpt3.5-turbo prompt to generate a label for the topic. The label is then written to a new\n",
    "    BQ table.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the query\n",
    "    query = replace_kwargs(\n",
    "        query=query,\n",
    "        UUID=UUID,\n",
    "        FEEDBACK_PROJECT=FEEDBACK_PROJECT,\n",
    "        TOPICS_TABLE=TOPICS_TABLE,\n",
    "        N_GRAM_TABLE=N_GRAM_TABLE,\n",
    "    )\n",
    "\n",
    "    # Run the query\n",
    "    results = run_query(query=query, project=FEEDBACK_PROJECT)\n",
    "\n",
    "    # Create a dictionary to store the top 10 rows for each topic\n",
    "    topic_dict = {}\n",
    "\n",
    "    # Iterate over the results\n",
    "    for row in results:\n",
    "        update_topic_dict(topic_dict, row)\n",
    "\n",
    "    # Iterate over the topics\n",
    "    for topic in topic_dict:\n",
    "        text_values = format_text_values(topic_dict[topic][\"text_value\"])\n",
    "        keywords = format_keywords(topic_dict[topic][\"keywords\"])\n",
    "\n",
    "        # Create a prompt\n",
    "        prompt = f\"\"\"\n",
    "        This is a list of texts where each collection of texts describe a topic. After each collection of texts, the name of the topic they represent is mentioned as a short-highly-descriptive title less than ten words long.\n",
    "        Instances of PII in the texts have been replaced with the type of PII surrounded by square brackets e.g. [PERSON_NAME]; these do not have any influence on the topic description.\n",
    "        ---\n",
    "        - I tried to renew the vehicle tax online several times today around 3.30pm, but on each occasion, after entering the 16 digit reference number, the system goes back to \"START\" again and again\n",
    "        - not accepting the reference number\n",
    "        - taxing my motor bike\n",
    "        - Would not accept 16 digit reference no either by phone or website\n",
    "\n",
    "        Keywords: tax car, try tax, tax vehicle, car tax, vehicle tax, try pay, road tax, not accept, debit card, tax try\n",
    "        Topic Name: Online vechile tax\n",
    "        ---\n",
    "        - My phone number no longer works and I can't go to my Universal Credit account\n",
    "        - No text messages received, all other details are correct but I cannot update my journal and I won't get paid this month if it isn't done soon.\n",
    "        - I am unable to sign in to my universal credit. The page is telling me that it is unavailable.\n",
    "        - My name is [PERSON_NAME], I am trying to sign into my account.\n",
    "\n",
    "        Keywords: universal credit, try sign, try log, account try, student finance, credit account, can not, sign universal, sign account, sign try\n",
    "        Topic Name: Universal credit / student finance sign in\n",
    "        ---\n",
    "        Topic:\n",
    "        Sample texts from this topic:\n",
    "        {text_values}\n",
    "        Keywords: {keywords}\n",
    "        Topic name:\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            completion = generate_completion(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI request failed: {e}\")\n",
    "\n",
    "        # Add the topic and label to the dictionary\n",
    "        topic_dict[topic][\"label\"] = completion.choices[0].message.content\n",
    "\n",
    "    return topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the OpenAI API to label our BERT topics\n",
    "query = read_sql_file(\"labels.sql\")\n",
    "\n",
    "labels = create_topic_labels(\n",
    "    query=query,\n",
    "    UUID=UUID,\n",
    "    FEEDBACK_PROJECT=FEEDBACK_PROJECT,\n",
    "    TOPICS_TABLE=BERT_TOPICS_TABLE,\n",
    "    N_GRAM_TABLE=BERT_TERMS_TABLE,\n",
    ")\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load topics over time data\n",
    "query = read_sql_file(\"generic_read_table.sql\")\n",
    "query = replace_kwargs(\n",
    "    query=query,\n",
    "    project=FEEDBACK_PROJECT,\n",
    "    table=BERT_TOT_TABLE,\n",
    "    uuid=UUID,\n",
    ")\n",
    "\n",
    "tot_data = load_data(query, FEEDBACK_PROJECT)\n",
    "\n",
    "# Visualise topics over time with natural language labels as legend\n",
    "topics = set(item[\"Topic\"] for item in tot_data)\n",
    "plot_data = {topic: {\"date\": [], \"value\": []} for topic in topics}\n",
    "\n",
    "for item in tot_data:\n",
    "    topic = item[\"Topic\"]\n",
    "    timestamp = item[\"Timestamp\"]\n",
    "    frequency = item[\"Frequency\"]\n",
    "\n",
    "    plot_data[topic][\"date\"].append(timestamp)\n",
    "    plot_data[topic][\"value\"].append(frequency)\n",
    "\n",
    "# Sort the date and value lists for each topic\n",
    "for topic in plot_data:\n",
    "    sorted_data = sorted(zip(plot_data[topic][\"date\"], plot_data[topic][\"value\"]))\n",
    "    sorted_dates, sorted_values = zip(*sorted_data)\n",
    "    plot_data[topic][\"date\"] = sorted_dates\n",
    "    plot_data[topic][\"value\"] = sorted_values\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adding traces\n",
    "for i, (topic, vals) in enumerate(plot_data.items()):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=vals[\"date\"],\n",
    "            y=vals[\"value\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=labels[topic][\"label\"],\n",
    "            marker=dict(symbol=i),\n",
    "            line_shape=\"spline\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Layout settings\n",
    "fig.update_layout(\n",
    "    # title=\"Topics Over Time Analysis\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    legend_title=\"Topic\",\n",
    "    legend=dict(orientation=\"h\", x=0.0, y=-0.15),\n",
    "    font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "    plot_bgcolor=\"white\",\n",
    "    xaxis=dict(\n",
    "        showline=True,\n",
    "        showgrid=True,\n",
    "        linecolor=\"black\",\n",
    "        tickmode=\"auto\",\n",
    "        nticks=15,\n",
    "        tickformat=\"%b %d\",\n",
    "    ),\n",
    "    yaxis=dict(showline=True, showgrid=True, linecolor=\"black\"),\n",
    "    margin=dict(l=20, r=20, t=40, b=80),\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the counts of topics\n",
    "query = read_sql_file(\"generic_read_table.sql\")\n",
    "query = replace_kwargs(\n",
    "    query=query,\n",
    "    project=FEEDBACK_PROJECT,\n",
    "    table=BERT_TOPICS_TABLE,\n",
    "    uuid=UUID,\n",
    ")\n",
    "\n",
    "results = load_data(query, FEEDBACK_PROJECT)\n",
    "\n",
    "# Get count of topics\n",
    "topic_counts = {}\n",
    "for row in results:\n",
    "    if row[\"topics\"] not in topic_counts:\n",
    "        topic_counts[row[\"topics\"]] = 0\n",
    "    topic_counts[row[\"topics\"]] += 1\n",
    "topic_counts\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Extract the topics and counts from the topic_counts dictionary\n",
    "topics = list(topic_counts.keys())\n",
    "topics = [labels[topic][\"label\"] for topic in topics]\n",
    "counts = list(topic_counts.values())\n",
    "\n",
    "# Create the bar chart\n",
    "fig = go.Figure(\n",
    "    data=go.Bar(\n",
    "        y=topics,\n",
    "        x=counts,\n",
    "        name=labels[topic][\"label\"],\n",
    "        orientation=\"h\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "fig.update_layout(\n",
    "    title=\"Topic Counts\",\n",
    "    xaxis_title=\"Topic\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    # legend_title=\"Topic\",\n",
    "    # legend=dict(orientation=\"h\", x=0.0, y=-0.15),\n",
    "    font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "    plot_bgcolor=\"white\",\n",
    "    xaxis=dict(\n",
    "        showline=True,\n",
    "        showgrid=True,\n",
    "        linecolor=\"black\",\n",
    "        tickmode=\"auto\",\n",
    "        nticks=15,\n",
    "        tickformat=\"%b %d\",\n",
    "    ),\n",
    "    yaxis=dict(showline=True, showgrid=True, linecolor=\"black\"),\n",
    "    margin=dict(l=20, r=20, t=40, b=80),\n",
    "    height=1000,\n",
    ")\n",
    "\n",
    "# Show the chart\n",
    "fig.show()\n",
    "\n",
    "# TODO: extend y axis so you can see all labels <- Note, added height=1000 to layout but not tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise sentiment over time\n",
    "query = read_sql_file(\"sentiment.sql\")\n",
    "query = replace_kwargs(\n",
    "    query=query,\n",
    "    project=FEEDBACK_PROJECT,\n",
    "    topics_table=BERT_TOPICS_TABLE,\n",
    "    process_table=PROCESS_TABLE,\n",
    "    uuid=UUID,\n",
    ")\n",
    "\n",
    "results = load_data(query, FEEDBACK_PROJECT)\n",
    "\n",
    "sentiment_counts = {}\n",
    "for record in results:\n",
    "    date_key = record[\"created\"].date()\n",
    "    sentiment = record[\"sentiment\"]\n",
    "    if date_key not in sentiment_counts:\n",
    "        sentiment_counts[date_key] = {}\n",
    "    if sentiment not in sentiment_counts[date_key]:\n",
    "        sentiment_counts[date_key][sentiment] = 0\n",
    "    sentiment_counts[date_key][sentiment] += 1\n",
    "\n",
    "dates = sorted(list(sentiment_counts.keys()))\n",
    "positive_counts = [sentiment_counts[date].get(\"POSITIVE\", 0) for date in dates]\n",
    "negative_counts = [sentiment_counts[date].get(\"NEGATIVE\", 0) for date in dates]\n",
    "neutral_counts = [sentiment_counts[date].get(\"NEUTRAL\", 0) for date in dates]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=dates,\n",
    "        y=positive_counts,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Positive\",\n",
    "        line_shape=\"spline\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=dates,\n",
    "        y=negative_counts,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Negative\",\n",
    "        line_shape=\"spline\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=dates,\n",
    "        y=neutral_counts,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Neutral\",\n",
    "        line_shape=\"spline\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Daily count of Positive, Neutral, and Negative comments\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Count\",\n",
    "    legend=dict(orientation=\"h\", x=0.0, y=-0.15),\n",
    "    font=dict(family=\"Helvetica\", size=12, color=\"black\"),\n",
    "    plot_bgcolor=\"white\",\n",
    "    xaxis=dict(\n",
    "        showline=True,\n",
    "        showgrid=True,\n",
    "        linecolor=\"black\",\n",
    "        tickmode=\"auto\",\n",
    "        nticks=15,\n",
    "        tickformat=\"%b %d\",\n",
    "    ),\n",
    "    yaxis=dict(showline=True, showgrid=True, linecolor=\"black\"),\n",
    "    margin=dict(l=20, r=20, t=40, b=80),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
