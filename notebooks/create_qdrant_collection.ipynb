{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  qdrant-client langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING QDRANT CLIENT\n",
    "\n",
    "import json\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "\n",
    "def create_qdrant_collection():\n",
    "    # Load data from JSON file\n",
    "    with open(\"data/test_1k_rows.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract text and vectors from data\n",
    "    texts = [item[\"response_value\"] for item in data]\n",
    "    vectors = [item[\"embeddings\"] for item in data]\n",
    "\n",
    "    # Initialize Qdrant client in local mode\n",
    "    client = QdrantClient()\n",
    "\n",
    "    # Create collection\n",
    "    collection_name = \"test_collection_1k_rows\"\n",
    "    client.create_collection(collection_name=collection_name)\n",
    "\n",
    "    # Insert documents into collection\n",
    "    for i, text in enumerate(texts):\n",
    "        vector = vectors[i]\n",
    "        document = {\"text\": text, \"vector\": vector}\n",
    "        client.insert(collection_name, [document])\n",
    "\n",
    "    print(f\"Qdrant collection '{collection_name}' created successfully.\")\n",
    "\n",
    "\n",
    "# Call the function to create the Qdrant collection\n",
    "create_qdrant_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING LANGCHAIN AND ASYNC\n",
    "\n",
    "import asyncio\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "\n",
    "def create_qdrant_collection():\n",
    "    # Load data from JSON file\n",
    "    with open(\"data/test_1k_rows.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract text and vectors from data\n",
    "    texts = [item[\"response_value\"] for item in data]\n",
    "    vectors = [item[\"embeddings\"] for item in data]\n",
    "    type = [item[\"type\"] for item in data]\n",
    "    created = [item[\"created\"] for item in data]\n",
    "    subject_page_path = [item[\"subject_page_path\"] for item in data]\n",
    "    feedack_record_id = [item[\"feedack_record_id\"] for item in data]\n",
    "    response_identifier = [item[\"response_identifier\"] for item in data]\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for i, text in enumerate(texts):\n",
    "        document = {\n",
    "            \"text\": text,\n",
    "            \"vector\": vectors[i],\n",
    "            \"metadata\": {\n",
    "                \"type\": type[i],\n",
    "                \"created\": created[i],\n",
    "                \"subject_page_path\": subject_page_path[i],\n",
    "                \"feedack_record_id\": feedack_record_id[i],\n",
    "                \"response_identifier\": response_identifier[i],\n",
    "            },\n",
    "        }\n",
    "        docs.append(document)\n",
    "\n",
    "    async def process_document(document):\n",
    "        try:\n",
    "            await Qdrant.from_documents(\n",
    "                documents=document,\n",
    "                url=\"localhost:6334\",\n",
    "                prefer_grpc=True,\n",
    "                collection_name=\"test_async_collection_1k_rows\",\n",
    "                force_recreate=False,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document: {e}\")\n",
    "\n",
    "        # create a list of tasks\n",
    "        tasks = [process_document(doc) for doc in docs]\n",
    "\n",
    "        # run all tasks concurrently\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    print(f\"Qdrant collection 'my_collection' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
